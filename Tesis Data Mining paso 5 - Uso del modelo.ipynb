{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os.path\n",
    "from os import path\n",
    "import sklearn.ensemble._forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargado del dataset original\n",
    "data = pd.read_csv(\"C:/Users/pjlu_/Desktop/DataminingUPB_2.csv\", sep=\";\")\n",
    "data.rename(columns={'Humedad en aire':'hum_aire',\n",
    "                          'Humedad en suelo 1':'hum_gnd_1',\n",
    "                          'Humedad en suelo 2':'hum_gnd_2',\n",
    "                          'Unnamed: 2':'unidad',\n",
    "                    'Unnamed: 4':'unidad_3',\n",
    "                    'Unnamed: 6':'unidad_5',\n",
    "                    'Unnamed: 8':'unidad_7',\n",
    "                    'Unnamed: 10':'unidad_9',\n",
    "                    'Unnamed: 12':'unidad_11'},\n",
    "                 inplace=True)\n",
    "\n",
    "## Borrado de columna de unidades\n",
    "data = data.drop([\"unidad\",\"unidad_3\",\"unidad_5\",\"unidad_7\",\"unidad_9\",\"unidad_11\"],axis =1)\n",
    "\n",
    "##Separado de los datos correspondientes al sujeto 1\n",
    "data2 = data.drop([\"EstadosPlanta_2\",\"N_hojas_2\",\"hum_gnd_2\",],axis =1)\n",
    "\n",
    "##Separado de los datos correspondientes al sujeto 2\n",
    "data3 = data.drop([\"EstadosPlanta_1\",\"N_hojas_1\",\"hum_gnd_1\"],axis =1)\n",
    "\n",
    "## Homogeneizado en encabezados de la tabla de datos de sujeto 1 y agregado de columna para la identificaciòn de estos\n",
    "data2.rename(columns={'hum_gnd_1':'hum_gnd','EstadosPlanta_1':'EstadosPlanta','N_hojas_1':'N_hojas'},inplace=True)\n",
    "data2['sujeto']= \"1\"\n",
    "\n",
    "## Homogeneizado en encabezados de la tabla de datos de sujeto 2 y agregado de columna para la identificaciòn de estos\n",
    "data3.rename(columns = {'hum_gnd_2':'hum_gnd','EstadosPlanta_2':'EstadosPlanta','N_hojas_2':'N_hojas'},inplace=True)\n",
    "data3['sujeto'] = \"2\"\n",
    "\n",
    "##Unión de los datos de sujetos 1 y 2 en un nuevo dataset\n",
    "data4 = pd.concat([data2,data3])\n",
    "\n",
    "## Eliminado de las columnas fecha y N_hojas\n",
    "data_nfecha = data4.drop([\"Time\",\"N_hojas\"],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divisiòn de dataset en predictores y target\n",
    "colnames = data_nfecha.columns.values.tolist()\n",
    "predictores = colnames\n",
    "target = colnames[5]\n",
    "predictores.remove('EstadosPlanta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(data_nfecha[predictores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdm_Frst = load('C:/Users/pjlu_/My Documents/EjerciciosMachineLearning/Random_Forest_Binario_Tesis.joblib') \n",
    "import pickle\n",
    "pkl_filename = \"C:/Users/pjlu_/My Documents/EjerciciosMachineLearning/Random_Forest_Binario_Tesis.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    rdm_Frst = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rdm_Frst.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EstadosPlanta_1'] =predictions[0]\n",
    "data['EstadosPlanta_2'] =predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists('C:/Users/pjlu_/My Documents/EjerciciosMachineLearning/DataMiningBI.csv')== True:\n",
    "    data.to_csv('C:/Users/pjlu_/My Documents/EjerciciosMachineLearning/DataMiningBI.csv', mode='a', header=False)\n",
    "else: data.to_csv('C:/Users/pjlu_/My Documents/EjerciciosMachineLearning/DataMiningBI.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
